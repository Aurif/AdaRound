{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e8befe2",
   "metadata": {},
   "source": [
    "### Pre-setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54e34c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH']='/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/targets/x86_64-linux/lib'\n",
    "os.environ['CUDA_TOOLKIT_PATH']='/usr/local/cuda'\n",
    "os.environ['CUDNN_INSTALL_PATH']='/usr/local/cuda'\n",
    "os.environ['CUDA_HOME']='/usr/local/cuda'\n",
    "os.environ['NVIDIA_DRIVER_CAPABILITIES']='compute,utility'\n",
    "os.environ['NVIDIA_VISIBLE_DEVICES']='all'\n",
    "os.environ['PYTHONPATH']='~/miniconda3/envs/py38/lib/python3.8/site-packages/aimet_common/x86_64-linux-gnu'\n",
    "os.environ['LD_LIBRARY_PATH'] +=':~/miniconda3/envs/py38/lib/python3.8/site-packages/aimet_common'\n",
    "os.environ['LD_LIBRARY_PATH'] +=':~/miniconda3/envs/py38/lib/python3.8/site-packages/aimet_common/x86_64-linux-gnu'\n",
    "os.environ['LD_LIBRARY_PATH'] +=':~/miniconda3/envs/py38/lib/python3.8/site-packages'\n",
    "os.environ['LD_LIBRARY_PATH'] +=':/usr/lib/x86_64-linux-gnu/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d211e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/miniconda3/envs/py38/lib/python3.8/site-packages/aimet_common')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ee75780",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd2e759",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T23:34:43.525487Z",
     "iopub.status.busy": "2023-05-14T23:34:43.525185Z",
     "iopub.status.idle": "2023-05-14T23:34:43.537880Z",
     "shell.execute_reply": "2023-05-14T23:34:43.536622Z"
    },
    "papermill": {
     "duration": 0.032565,
     "end_time": "2023-05-14T23:34:43.539966",
     "exception": false,
     "start_time": "2023-05-14T23:34:43.507401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "########################################################################################\n",
    "# from Examples.common.utils import accuracy\n",
    "########################################################################################\n",
    "# =============================================================================\n",
    "#\n",
    "#  @@-COPYRIGHT-START-@@\n",
    "#\n",
    "#  Copyright (c) 2018, Qualcomm Innovation Center, Inc. All rights reserved.\n",
    "#\n",
    "#  Redistribution and use in source and binary forms, with or without\n",
    "#  modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  1. Redistributions of source code must retain the above copyright notice,\n",
    "#     this list of conditions and the following disclaimer.\n",
    "#\n",
    "#  2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#     this list of conditions and the following disclaimer in the documentation\n",
    "#     and/or other materials provided with the distribution.\n",
    "#\n",
    "#  3. Neither the name of the copyright holder nor the names of its contributors\n",
    "#     may be used to endorse or promote products derived from this software\n",
    "#     without specific prior written permission.\n",
    "#\n",
    "#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "#  POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "#  SPDX-License-Identifier: BSD-3-Clause\n",
    "#\n",
    "#  @@-COPYRIGHT-END-@@\n",
    "#\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "General utility functions for AIMET examples\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "\n",
    "    return res\n",
    "########################################################################################\n",
    "\n",
    "import math\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "##############################################################################################################\n",
    "# from Examples.torch.utils.image_net_evaluator import ImageNetEvaluator\n",
    "##############################################################################################################\n",
    "\n",
    "\n",
    "# !/usr/bin/env python\n",
    "# =============================================================================\n",
    "#  @@-COPYRIGHT-START-@@\n",
    "#\n",
    "#  Copyright (c) 2021, Qualcomm Innovation Center, Inc. All rights reserved.\n",
    "#\n",
    "#  Redistribution and use in source and binary forms, with or without\n",
    "#  modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  1. Redistributions of source code must retain the above copyright notice,\n",
    "#     this list of conditions and the following disclaimer.\n",
    "#\n",
    "#  2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#     this list of conditions and the following disclaimer in the documentation\n",
    "#     and/or other materials provided with the distribution.\n",
    "#\n",
    "#  3. Neither the name of the copyright holder nor the names of its contributors\n",
    "#     may be used to endorse or promote products derived from this software\n",
    "#     without specific prior written permission.\n",
    "#\n",
    "#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "#  POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "#  SPDX-License-Identifier: BSD-3-Clause\n",
    "#\n",
    "#  @@-COPYRIGHT-END-@@\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Creates Evaluator for Image-Net dataset\n",
    "\"\"\"\n",
    "import logging\n",
    "\n",
    "import progressbar\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "logger = logging.getLogger('Eval')\n",
    "\n",
    "\n",
    "class ImageNetEvaluator:\n",
    "    \"\"\"\n",
    "    For validation of a trained model using the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, images_dir: str, image_size: int, batch_size: int = 128,\n",
    "                 num_workers: int = 32, num_val_samples_per_class: int = None):\n",
    "        \"\"\"\n",
    "        :param images_dir: The path to the data directory\n",
    "        :param image_size: The length of the image\n",
    "        :param batch_size: The batch size to use for training and validation\n",
    "        :param num_workers: Indiicates to the data loader how many sub-processes to use for data loading.\n",
    "        :param num_train_samples_per_class: Number of samples to use per class.\n",
    "        \"\"\"\n",
    "        self._val_data_loader = ImageNetDataLoader(images_dir,\n",
    "                                                   image_size=image_size,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   is_training=False,\n",
    "                                                   num_workers=num_workers,\n",
    "                                                   num_samples_per_class=num_val_samples_per_class).data_loader\n",
    "\n",
    "    def evaluate(self, model: nn.Module, iterations: int = None, use_cuda: bool = False) -> float:\n",
    "        \"\"\"\n",
    "        Evaluate the specified model using the specified number of samples batches from the\n",
    "        validation set.\n",
    "        :param model: The model to be evaluated.\n",
    "        :param iterations: The number of batches to use from the validation set.\n",
    "        :param use_cuda: If True then use a GPU for inference.\n",
    "        :return: The accuracy for the sample with the maximum accuracy.\n",
    "        \"\"\"\n",
    "\n",
    "        device = torch.device('cpu')\n",
    "        if use_cuda:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                logger.error('use_cuda is selected but no cuda device found.')\n",
    "                raise RuntimeError(\"Found no CUDA Device while use_cuda is selected\")\n",
    "\n",
    "        if iterations is None:\n",
    "            logger.info('No value of iteration is provided, running evaluation on complete dataset.')\n",
    "            iterations = len(self._val_data_loader)\n",
    "        if iterations <= 0:\n",
    "            logger.error('Cannot evaluate on %d iterations', iterations)\n",
    "\n",
    "        acc_top1 = 0\n",
    "        acc_top5 = 0\n",
    "\n",
    "        logger.info(\"Evaluating nn.Module for %d iterations with batch_size %d\",\n",
    "                    iterations, self._val_data_loader.batch_size)\n",
    "\n",
    "        model = model.to(device)\n",
    "        model = model.eval()\n",
    "\n",
    "        batch_cntr = 1\n",
    "        with progressbar.ProgressBar(max_value=iterations) as progress_bar:\n",
    "            with torch.no_grad():\n",
    "                for input_data, target_data in self._val_data_loader:\n",
    "\n",
    "                    inputs_batch = input_data.to(device)\n",
    "                    target_batch = target_data.to(device)\n",
    "\n",
    "                    predicted_batch = model(inputs_batch)\n",
    "\n",
    "                    batch_avg_top_1_5 = accuracy(output=predicted_batch, target=target_batch,\n",
    "                                                 topk=(1, 5))\n",
    "\n",
    "                    acc_top1 += batch_avg_top_1_5[0].item()\n",
    "                    acc_top5 += batch_avg_top_1_5[1].item()\n",
    "\n",
    "                    progress_bar.update(batch_cntr)\n",
    "\n",
    "                    batch_cntr += 1\n",
    "                    if batch_cntr > iterations:\n",
    "                        break\n",
    "\n",
    "        acc_top1 /= iterations\n",
    "        acc_top5 /= iterations\n",
    "\n",
    "        logger.info('Avg accuracy Top 1: %f Avg accuracy Top 5: %f on validation Dataset',\n",
    "                    acc_top1, acc_top5)\n",
    "\n",
    "        return acc_top1\n",
    "###################################################################################################################\n",
    "\n",
    "\n",
    "###################################################################################################################\n",
    "#from Examples.torch.utils.image_net_data_loader import ImageNetDataLoader \n",
    "###################################################################################################################\n",
    "# !/usr/bin/env python\n",
    "# =============================================================================\n",
    "#  @@-COPYRIGHT-START-@@\n",
    "#\n",
    "#  Copyright (c) 2021, Qualcomm Innovation Center, Inc. All rights reserved.\n",
    "#\n",
    "#  Redistribution and use in source and binary forms, with or without\n",
    "#  modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  1. Redistributions of source code must retain the above copyright notice,\n",
    "#     this list of conditions and the following disclaimer.\n",
    "#\n",
    "#  2. Redistributions in binary form must reproduce the above copyright notice,\n",
    "#     this list of conditions and the following disclaimer in the documentation\n",
    "#     and/or other materials provided with the distribution.\n",
    "#\n",
    "#  3. Neither the name of the copyright holder nor the names of its contributors\n",
    "#     may be used to endorse or promote products derived from this software\n",
    "#     without specific prior written permission.\n",
    "#\n",
    "#  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n",
    "#  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n",
    "#  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n",
    "#  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n",
    "#  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n",
    "#  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n",
    "#  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n",
    "#  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n",
    "#  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "#  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "#  POSSIBILITY OF SUCH DAMAGE.\n",
    "#\n",
    "#  SPDX-License-Identifier: BSD-3-Clause\n",
    "#\n",
    "#  @@-COPYRIGHT-END-@@\n",
    "# =============================================================================\n",
    "\n",
    "\"\"\"\n",
    "Creates data-loader for Image-Net dataset\n",
    "\"\"\"\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets.folder import default_loader, has_file_allowed_extension\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as torch_data\n",
    "\n",
    "\n",
    "logger = logging.getLogger('Dataloader')\n",
    "\n",
    "IMG_EXTENSIONS = '.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif'\n",
    "\n",
    "\n",
    "def make_dataset(directory: str, class_to_idx: dict, extensions: tuple, num_samples_per_class: int) -> list:\n",
    "    \"\"\"\n",
    "    Creates a dataset of images with num_samples_per_class images in each class\n",
    "\n",
    "    :param directory: The string path to the data directory.\n",
    "    :param class_to_idx: A dictionary mapping the name of the class to the index (label)\n",
    "    :param extensions: list of valid extensions to load data\n",
    "    :param num_samples_per_class: Number of samples to use per class.\n",
    "\n",
    "    :return: list of images containing the entire dataset.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    num_classes = 0\n",
    "    directory = os.path.expanduser(directory)\n",
    "    for class_name in sorted(class_to_idx.keys()):\n",
    "        class_path = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_idx = class_to_idx[class_name]\n",
    "            class_images = add_images_for_class(class_path, extensions, num_samples_per_class, class_idx)\n",
    "            images.extend(class_images)\n",
    "            num_classes += 1\n",
    "        if num_samples_per_class and num_classes >= num_samples_per_class:\n",
    "            break\n",
    "\n",
    "    \n",
    "    logger.info(\"Dataset consists of %d images in %d classes\", len(images), num_classes)\n",
    "    random.shuffle(images)\n",
    "    return images\n",
    "\n",
    "\n",
    "def add_images_for_class(class_path: str, extensions: tuple, num_samples_per_class: int, class_idx: int) -> list:\n",
    "    \"\"\"\n",
    "    For a given class, adds num_samples_per_class images to a list.\n",
    "\n",
    "    :param class_path: The string path to the class directory.\n",
    "    :param extensions: List of valid extensions to load data\n",
    "    :param num_samples_per_class: Number of samples to use per class.\n",
    "    :param class_idx: numerical index of class.\n",
    "\n",
    "    :return: list of images for given class.\n",
    "    \"\"\"\n",
    "    class_images = []\n",
    "    count = 0\n",
    "    for file_name in os.listdir(class_path):\n",
    "        if num_samples_per_class and count >= num_samples_per_class:\n",
    "            break\n",
    "        if has_file_allowed_extension(file_name, extensions):\n",
    "            image_path = os.path.join(class_path, file_name)\n",
    "            item = (image_path, class_idx)\n",
    "            class_images.append(item)\n",
    "            count += 1\n",
    "\n",
    "    return class_images\n",
    "\n",
    "\n",
    "class ImageFolder(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class inspired by torchvision.datasets.folder.DatasetFolder for images organized as\n",
    "        individual files grouped by category.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root: str, transform=None, target_transform=None,\n",
    "                 num_samples_per_class: int = None):\n",
    "\n",
    "        \"\"\"\n",
    "        :param root: The path to the data directory.\n",
    "        :param transform: The required processing to be applied on the sample.\n",
    "        :param target_transform:  The required processing to be applied on the target.\n",
    "        :param num_samples_per_class: Number of samples to use per class.\n",
    "\n",
    "        \"\"\"\n",
    "        Dataset.__init__(self)\n",
    "        classes, class_to_idx = self._find_classes(root)\n",
    "        self.samples = make_dataset(root, class_to_idx, IMG_EXTENSIONS, num_samples_per_class)\n",
    "        if not self.samples:\n",
    "            raise (RuntimeError(\n",
    "                \"Found 0 files in sub folders of: {}\\nSupported extensions are: {}\".format(\n",
    "                    root, \",\".join(IMG_EXTENSIONS))))\n",
    "\n",
    "        self.root = root\n",
    "        self.loader = default_loader\n",
    "        self.extensions = IMG_EXTENSIONS\n",
    "\n",
    "        self.classes = classes\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.targets = [s[1] for s in self.samples]\n",
    "\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        self.imgs = self.samples\n",
    "\n",
    "    @staticmethod\n",
    "    def _find_classes(directory: str):\n",
    "        classes = [d for d in os.listdir(directory) if\n",
    "                   os.path.isdir(os.path.join(directory, d))]\n",
    "        classes.sort()\n",
    "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
    "        return classes, class_to_idx\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        path, target = self.samples[index]\n",
    "        sample = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "\n",
    "class ImageNetDataLoader:\n",
    "    \"\"\"\n",
    "    For loading Validation data from the ImageNet dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, images_dir: str, image_size: int, batch_size: int = 128,\n",
    "                 is_training: bool = False, num_workers: int = 8, num_samples_per_class: int = None):\n",
    "        \"\"\"\n",
    "        :param images_dir: The path to the data directory\n",
    "        :param image_size: The length of the image\n",
    "        :param batch_size: The batch size to use for training and validation\n",
    "        :param is_training: Indicates whether to load the training or validation data\n",
    "        :param num_workers: Indiicates to the data loader how many sub-processes to use for data loading.\n",
    "        :param num_samples_per_class: Number of samples to use per class.\n",
    "        \"\"\"\n",
    "\n",
    "        # For normalization, mean and std dev values are calculated per channel\n",
    "        # and can be found on the web.\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "        self.train_transforms = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "\n",
    "        self.val_transforms = transforms.Compose([\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            normalize])\n",
    "\n",
    "        if is_training:\n",
    "            data_set = ImageFolder(\n",
    "                root=os.path.join(images_dir, 'train'), transform=self.train_transforms,\n",
    "                num_samples_per_class=num_samples_per_class)\n",
    "        else:\n",
    "            data_set = ImageFolder(\n",
    "                root=os.path.join(images_dir, 'val'), transform=self.val_transforms,\n",
    "                num_samples_per_class=num_samples_per_class)\n",
    "\n",
    "        self._data_loader = torch_data.DataLoader(\n",
    "            data_set, batch_size=batch_size, shuffle=is_training,\n",
    "            num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "    @property\n",
    "    def data_loader(self) -> torch_data.DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the data-loader\n",
    "        \"\"\"\n",
    "        return self._data_loader\n",
    "###################################################################################################################\n",
    "\n",
    "class ImageNetDataPipeline:\n",
    "\n",
    "    @staticmethod\n",
    "    def get_val_dataloader(DATASET_DIR, N, batch_size, image_size) -> torch.utils.data.DataLoader:\n",
    "        \"\"\"\n",
    "        Instantiates a validation dataloader for ImageNet dataset and returns it\n",
    "        \"\"\"\n",
    "        data_loader = ImageNetDataLoader(DATASET_DIR,\n",
    "                                         image_size=image_size,\n",
    "                                         batch_size=batch_size,\n",
    "                                         is_training=False,\n",
    "                                         num_workers=1,\n",
    "                                         num_samples_per_class=N).data_loader\n",
    "        return data_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def evaluate(model: torch.nn.Module, use_cuda: bool, DATASET_DIR, N, batch_size, image_size) -> float:\n",
    "        \"\"\"\n",
    "        Given a torch model, evaluates its Top-1 accuracy on the dataset\n",
    "        :param model: the model to evaluate\n",
    "        :param use_cuda: whether or not the GPU should be used.\n",
    "        \"\"\"\n",
    "        evaluator = ImageNetEvaluator(DATASET_DIR, image_size=image_size,\n",
    "                                      batch_size=batch_size,\n",
    "                                      num_workers=1,\n",
    "                                      num_val_samples_per_class=N)\n",
    "\n",
    "        return evaluator.evaluate(model, iterations=None, use_cuda=use_cuda)\n",
    "    \n",
    "\n",
    "def get_pass_calibration_data(SAMPLES_TO_COMPUTE_ENCODINGS, DATASET_DIR, N, batch_size, image_size):\n",
    "    def pass_calibration_data(sim_model, use_cuda, DATASET_DIR, N, batch_size, image_size):\n",
    "        data_loader = ImageNetDataPipeline.get_val_dataloader(DATASET_DIR, N, batch_size, image_size)\n",
    "        batch_size = data_loader.batch_size\n",
    "\n",
    "        if use_cuda:\n",
    "            device = torch.device('cuda')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "\n",
    "        sim_model.eval()\n",
    "        samples = SAMPLES_TO_COMPUTE_ENCODINGS\n",
    "\n",
    "        batch_cntr = 0\n",
    "        with torch.no_grad():\n",
    "            for input_data, target_data in data_loader:\n",
    "\n",
    "                inputs_batch = input_data.to(device)\n",
    "                sim_model(inputs_batch)\n",
    "\n",
    "                batch_cntr += 1\n",
    "                if (batch_cntr * batch_size) > samples:\n",
    "                    break\n",
    "    return lambda sim_model, use_cuda: pass_calibration_data(sim_model, use_cuda, DATASET_DIR, N, batch_size, image_size)\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "###########################################################################################################\n",
    "\n",
    "def run_experiment(model, ROOT_DATA_AND_OUTPUTS, DATASET_FOLDER_PATH, N, IMAGE_SIZE, BATCH_SIZE, BIWIDTH,\n",
    "                   BIWIDTH_ACTIVATION, SAMPLES_TO_COMPUTE_ENCODINGS, ADAROUND_ITERATIONS, ADAROUND_NUM_BATCHES,\n",
    "                   QUANT_SCHEME, output_dir):\n",
    "\n",
    "\n",
    "    import os\n",
    "    DATASET_DIR = f'{ROOT_DATA_AND_OUTPUTS}{DATASET_FOLDER_PATH}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    from aimet_torch.model_preparer import prepare_model\n",
    "    model = prepare_model(model)\n",
    "    use_cuda = False\n",
    "    if torch.cuda.is_available():\n",
    "        use_cuda = True\n",
    "        model.to(torch.device('cuda'))\n",
    "    print('Using cuda: {}'.format(use_cuda))\n",
    "\n",
    "    pass_calibration_data = get_pass_calibration_data(SAMPLES_TO_COMPUTE_ENCODINGS, DATASET_DIR, N, BATCH_SIZE, IMAGE_SIZE)\n",
    "\n",
    "    ############################################################### original accuracy - start\n",
    "    accuracy = ImageNetDataPipeline.evaluate(model, use_cuda, DATASET_DIR, N, BATCH_SIZE, IMAGE_SIZE)\n",
    "    print(accuracy)\n",
    "\n",
    "    original_accuracy = accuracy\n",
    "    ############################################################### original accuracy - end\n",
    "    \n",
    "    from aimet_torch.batch_norm_fold import fold_all_batch_norms\n",
    "\n",
    "    _ = fold_all_batch_norms(model, input_shapes=(1, 3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "    from aimet_common.defs import QuantScheme\n",
    "    from aimet_torch.quantsim import QuantizationSimModel\n",
    "\n",
    "    dummy_input = torch.rand(1, 3, IMAGE_SIZE, IMAGE_SIZE)   \n",
    "    if use_cuda:\n",
    "        dummy_input = dummy_input.cuda()\n",
    "\n",
    "    quant_scheme = QuantScheme.post_training_tf_enhanced if QUANT_SCHEME == 'tf_enhanced' else QuantScheme.post_training_tf\n",
    "\n",
    "    ############################################################### quantized accuracy - nearest - start\n",
    "    sim = QuantizationSimModel(model=model,\n",
    "                            quant_scheme=quant_scheme,\n",
    "                            dummy_input=dummy_input,\n",
    "                            rounding_mode = 'nearest',\n",
    "                            default_output_bw=BIWIDTH_ACTIVATION,\n",
    "                            default_param_bw=BIWIDTH)\n",
    "    \n",
    "\n",
    "    sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                        forward_pass_callback_args=use_cuda)\n",
    "\n",
    "    accuracy = ImageNetDataPipeline.evaluate(sim.model, use_cuda, DATASET_DIR, N, BATCH_SIZE, IMAGE_SIZE)\n",
    "    print(accuracy)\n",
    "    quantized_accuracy_nearest = accuracy\n",
    "    ############################################################### quantized accuracy - nearest - end\n",
    "\n",
    "\n",
    "    ############################################################### quantized accuracy - stochastic - start\n",
    "    sim = QuantizationSimModel(model=model,\n",
    "                            quant_scheme=quant_scheme,\n",
    "                            dummy_input=dummy_input,\n",
    "                            rounding_mode = 'stochastic',\n",
    "                            default_output_bw=BIWIDTH_ACTIVATION,\n",
    "                            default_param_bw=BIWIDTH)\n",
    "    \n",
    "\n",
    "    sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                        forward_pass_callback_args=use_cuda)\n",
    "\n",
    "    accuracy = ImageNetDataPipeline.evaluate(sim.model, use_cuda, DATASET_DIR, N, BATCH_SIZE, IMAGE_SIZE)\n",
    "    print(accuracy)\n",
    "    quantized_accuracy_stochastic = accuracy\n",
    "    ############################################################### quantized accuracy - stochastic - end\n",
    "\n",
    "    ############################################################### quantized accuracy - adaround - start\n",
    "\n",
    "    from aimet_torch.adaround.adaround_weight import Adaround, AdaroundParameters\n",
    "\n",
    "    data_loader = ImageNetDataPipeline.get_val_dataloader(DATASET_DIR, N, BATCH_SIZE, IMAGE_SIZE)\n",
    "    params = AdaroundParameters(data_loader=data_loader, num_batches=ADAROUND_NUM_BATCHES, default_num_iterations=ADAROUND_ITERATIONS)\n",
    "\n",
    "    dummy_input = torch.rand(1, 3, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    if use_cuda:\n",
    "        dummy_input = dummy_input.cuda()\n",
    "\n",
    "    ada_model = Adaround.apply_adaround(model, dummy_input, params,\n",
    "                                        path=f'{output_dir}', \n",
    "                                        filename_prefix='adaround', \n",
    "                                        default_param_bw=BIWIDTH,\n",
    "                                        default_quant_scheme=quant_scheme)\n",
    "    \n",
    "    sim = QuantizationSimModel(model=ada_model,\n",
    "                            dummy_input=dummy_input,\n",
    "                            quant_scheme=quant_scheme,\n",
    "                            default_output_bw=BIWIDTH_ACTIVATION, \n",
    "                            default_param_bw=BIWIDTH)\n",
    "\n",
    "    sim.set_and_freeze_param_encodings(encoding_path=f'{output_dir}adaround.encodings')\n",
    "\n",
    "    sim.compute_encodings(forward_pass_callback=pass_calibration_data,\n",
    "                        forward_pass_callback_args=use_cuda)\n",
    "    \n",
    "    accuracy = ImageNetDataPipeline.evaluate(sim.model, use_cuda, DATASET_DIR, N, BATCH_SIZE, IMAGE_SIZE)\n",
    "    print(accuracy)\n",
    "    quantized_accuracy_adaround = accuracy\n",
    "\n",
    "    from aimet_torch import quantsim \n",
    "    quantsim.save_checkpoint(quant_sim_model=sim, file_path=f'{output_dir}/sim_after_adaround_checkpoint.pth')\n",
    "\n",
    "    ############################################################### quantized accuracy - adaround - end\n",
    "    \n",
    "    results = {\n",
    "        'original_accuracy': original_accuracy,\n",
    "        'quantized_accuracy_nearest': quantized_accuracy_nearest,\n",
    "        'quantized_accuracy_stochastic': quantized_accuracy_stochastic,\n",
    "        'quantized_accuracy_adaround': quantized_accuracy_adaround\n",
    "    }\n",
    "    return results\n",
    "\n",
    "################################################################################################ end of functions. usage below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b894f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import experimentize as E\n",
    "import torch\n",
    "import datetime\n",
    "\n",
    "ROOT_DATA_AND_OUTPUTS = './../'\n",
    "class Params(E.ParamsBase):\n",
    "    DATASET = 'cifar10'\n",
    "    # available model names\n",
    "    # ['cifar100_mobilenetv2_x0_5',\n",
    "    #  'cifar100_mobilenetv2_x0_75',\n",
    "    #  'cifar100_mobilenetv2_x1_0',\n",
    "    #  'cifar100_mobilenetv2_x1_4',\n",
    "    #  'cifar10_mobilenetv2_x0_5',\n",
    "    #  'cifar10_mobilenetv2_x0_75',\n",
    "    #  'cifar10_mobilenetv2_x1_0',\n",
    "    #  'cifar10_mobilenetv2_x1_4']\n",
    "    MODEL_NAME = 'cifar10_mobilenetv2_x0_5'\n",
    "\n",
    "    BATCH_SIZE = 32\n",
    "    SAMPLES_TO_COMPUTE_ENCODINGS = 1000\n",
    "    QUANT_SCHEME = 'tf_enhanced' # 'tf_enhanced' or 'tf'\n",
    "    BIWIDTH = 4\n",
    "    BIWIDTH_ACTIVATION = 8 #quantization on the input and output of the layer\n",
    "\n",
    "    ADAROUND_ITERATIONS = 10000\n",
    "    ADAROUND_NUM_BATCHES = 32\n",
    "    \n",
    "    \n",
    "\n",
    "datasets = {\n",
    "    'cifar10': {\n",
    "        'PATH': 'input/cifar10/',\n",
    "        'IMAGE_SIZE': 32,\n",
    "        'CLASS_COUNT': 10\n",
    "    },\n",
    "}\n",
    "\n",
    "@E.experimentize(Params)\n",
    "class Experiment:\n",
    "    def run(self, *, MODEL_NAME=E.param(), DATASET=E.param(), BATCH_SIZE=E.param(), SAMPLES_TO_COMPUTE_ENCODINGS=E.param(), \n",
    "            BIWIDTH=E.param(), BIWIDTH_ACTIVATION=E.param(), ADAROUND_ITERATIONS=E.param(), ADAROUND_NUM_BATCHES=E.param(),\n",
    "            QUANT_SCHEME=E.param(), iteration=E.param()):\n",
    "        random.seed(iteration)\n",
    "\n",
    "        m = torch.hub.list(\"chenyaofo/pytorch-cifar-models\", force_reload=True)\n",
    "        if MODEL_NAME not in m:\n",
    "            raise Exception(\"model {MODEL_NAME} not found in {m}\")\n",
    "        model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", MODEL_NAME, pretrained=True)\n",
    "\n",
    "        DATASET_FOLDER_PATH = datasets[DATASET]['PATH']\n",
    "        IMAGE_SIZE = datasets[DATASET]['IMAGE_SIZE']\n",
    "        CLASS_COUNT = datasets[DATASET]['CLASS_COUNT']\n",
    "        N = math.ceil(BATCH_SIZE*32/CLASS_COUNT) # number of classes and samples per class\n",
    "\n",
    "        output_dir = f'{ROOT_DATA_AND_OUTPUTS}output/{datetime.datetime.now().strftime(\"%Y%m%d\")}/{datetime.datetime.now().strftime(\"%H%M%S\")}/'\n",
    "\n",
    "        return run_experiment(model, ROOT_DATA_AND_OUTPUTS, DATASET_FOLDER_PATH, N, IMAGE_SIZE, BATCH_SIZE, BIWIDTH,\n",
    "                        BIWIDTH_ACTIVATION, SAMPLES_TO_COMPUTE_ENCODINGS, ADAROUND_ITERATIONS, ADAROUND_NUM_BATCHES,\n",
    "                        QUANT_SCHEME, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f130279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "REPETITIONS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b869e09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>ADAROUND_ITERATIONS</th>\n",
       "      <th>original_accuracy</th>\n",
       "      <th>quantized_accuracy_nearest</th>\n",
       "      <th>quantized_accuracy_stochastic</th>\n",
       "      <th>quantized_accuracy_adaround</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>91.256313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>91.856061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>91.540404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>92.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>5000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>91.919192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>92.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>91.856061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>91.635101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>15000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>91.761364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>15000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>91.856061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>15000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>92.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>20000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>91.761364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.140152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>20000</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>92.108586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  ADAROUND_ITERATIONS  original_accuracy  \\\n",
       "0           0                 1000          92.992424   \n",
       "5           1                 1000          92.992424   \n",
       "6           2                 1000          92.992424   \n",
       "1           0                 5000          92.992424   \n",
       "7           1                 5000          92.992424   \n",
       "8           2                 5000          92.992424   \n",
       "2           0                10000          92.992424   \n",
       "9           1                10000          92.992424   \n",
       "10          2                10000          92.992424   \n",
       "3           0                15000          92.992424   \n",
       "11          1                15000          92.992424   \n",
       "12          2                15000          92.992424   \n",
       "4           0                20000          92.992424   \n",
       "13          1                20000          92.992424   \n",
       "14          2                20000          92.992424   \n",
       "\n",
       "    quantized_accuracy_nearest  quantized_accuracy_stochastic  \\\n",
       "0                    80.271464                      80.271464   \n",
       "5                    79.671717                      79.892677   \n",
       "6                    79.482323                      79.071970   \n",
       "1                    80.271464                      80.271464   \n",
       "7                    79.671717                      79.892677   \n",
       "8                    79.482323                      79.071970   \n",
       "2                    80.271464                      80.271464   \n",
       "9                    79.671717                      79.892677   \n",
       "10                   79.482323                      79.071970   \n",
       "3                    80.271464                      80.271464   \n",
       "11                   79.671717                      79.892677   \n",
       "12                   79.482323                      79.071970   \n",
       "4                    80.271464                      80.271464   \n",
       "13                   79.671717                      79.892677   \n",
       "14                   79.482323                      79.071970   \n",
       "\n",
       "    quantized_accuracy_adaround  \n",
       "0                     91.256313  \n",
       "5                     91.856061  \n",
       "6                     91.540404  \n",
       "1                     92.234848  \n",
       "7                     92.234848  \n",
       "8                     91.919192  \n",
       "2                     92.613636  \n",
       "9                     91.856061  \n",
       "10                    91.635101  \n",
       "3                     91.761364  \n",
       "11                    91.856061  \n",
       "12                    92.013889  \n",
       "4                     91.761364  \n",
       "13                    92.140152  \n",
       "14                    92.108586  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment().run(E.AsExperiment([\n",
    "    Params(ADAROUND_ITERATIONS=it) for it in [1000, 5000, 10000, 15000, 20000]\n",
    "], repetitions=REPETITIONS, with_cache=\"../results/ADAROUND_ITERATIONS\"))().sort_values(by=['ADAROUND_ITERATIONS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8784d1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADAROUND_NUM_BATCHES</th>\n",
       "      <th>iteration</th>\n",
       "      <th>original_accuracy</th>\n",
       "      <th>quantized_accuracy_nearest</th>\n",
       "      <th>quantized_accuracy_stochastic</th>\n",
       "      <th>quantized_accuracy_adaround</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.681818</td>\n",
       "      <td>80.555555</td>\n",
       "      <td>92.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.140152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>92.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.681818</td>\n",
       "      <td>80.555555</td>\n",
       "      <td>92.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.518939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>92.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.681818</td>\n",
       "      <td>80.555555</td>\n",
       "      <td>91.161616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>91.950758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>91.824495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.681818</td>\n",
       "      <td>80.555555</td>\n",
       "      <td>91.824495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>91.540404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ADAROUND_NUM_BATCHES  iteration  original_accuracy  \\\n",
       "0                      8          0          92.992424   \n",
       "1                      8          1          92.992424   \n",
       "2                      8          2          92.992424   \n",
       "3                     16          0          92.992424   \n",
       "4                     16          1          92.992424   \n",
       "5                     16          2          92.992424   \n",
       "6                     24          0          92.992424   \n",
       "7                     24          1          92.992424   \n",
       "8                     24          2          92.992424   \n",
       "9                     32          0          92.992424   \n",
       "10                    32          1          92.992424   \n",
       "11                    32          2          92.992424   \n",
       "\n",
       "    quantized_accuracy_nearest  quantized_accuracy_stochastic  \\\n",
       "0                    80.681818                      80.555555   \n",
       "1                    79.671717                      79.892677   \n",
       "2                    79.482323                      79.071970   \n",
       "3                    80.681818                      80.555555   \n",
       "4                    79.671717                      79.892677   \n",
       "5                    79.482323                      79.071970   \n",
       "6                    80.681818                      80.555555   \n",
       "7                    79.671717                      79.892677   \n",
       "8                    79.482323                      79.071970   \n",
       "9                    80.681818                      80.555555   \n",
       "10                   79.671717                      79.892677   \n",
       "11                   79.482323                      79.071970   \n",
       "\n",
       "    quantized_accuracy_adaround  \n",
       "0                     92.013889  \n",
       "1                     92.140152  \n",
       "2                     92.013889  \n",
       "3                     92.013889  \n",
       "4                     92.518939  \n",
       "5                     92.013889  \n",
       "6                     91.161616  \n",
       "7                     91.950758  \n",
       "8                     91.824495  \n",
       "9                     91.824495  \n",
       "10                    92.234848  \n",
       "11                    91.540404  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment().run(E.AsExperiment([\n",
    "    Params(ADAROUND_NUM_BATCHES=i) for i in [8, 16, 24, 32]\n",
    "], repetitions=REPETITIONS, with_cache=\"../results/ADAROUND_NUM_BATCHES\"))()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d658e51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>QUANT_SCHEME</th>\n",
       "      <th>original_accuracy</th>\n",
       "      <th>quantized_accuracy_nearest</th>\n",
       "      <th>quantized_accuracy_stochastic</th>\n",
       "      <th>quantized_accuracy_adaround</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tf</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>91.571970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tf</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>65.972222</td>\n",
       "      <td>65.688131</td>\n",
       "      <td>92.234848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>tf</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>64.457071</td>\n",
       "      <td>64.457071</td>\n",
       "      <td>92.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tf_enhanced</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>91.761364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>tf_enhanced</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>tf_enhanced</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>91.824495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   iteration QUANT_SCHEME  original_accuracy  quantized_accuracy_nearest  \\\n",
       "1          0           tf          92.992424                   66.666667   \n",
       "4          1           tf          92.992424                   65.972222   \n",
       "5          2           tf          92.992424                   64.457071   \n",
       "0          0  tf_enhanced          92.992424                   80.271464   \n",
       "2          1  tf_enhanced          92.992424                   79.671717   \n",
       "3          2  tf_enhanced          92.992424                   79.482323   \n",
       "\n",
       "   quantized_accuracy_stochastic  quantized_accuracy_adaround  \n",
       "1                      66.666667                    91.571970  \n",
       "4                      65.688131                    92.234848  \n",
       "5                      64.457071                    92.013889  \n",
       "0                      80.271464                    91.761364  \n",
       "2                      79.892677                    92.424242  \n",
       "3                      79.071970                    91.824495  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment().run(E.AsExperiment([\n",
    "    Params(QUANT_SCHEME=i) for i in ['tf_enhanced', 'tf']\n",
    "], repetitions=REPETITIONS, with_cache=\"../results/QUANT_SCHEME\"))().sort_values(by=['QUANT_SCHEME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58f26409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>iteration</th>\n",
       "      <th>BIWIDTH</th>\n",
       "      <th>BIWIDTH_ACTIVATION</th>\n",
       "      <th>original_accuracy</th>\n",
       "      <th>quantized_accuracy_nearest</th>\n",
       "      <th>quantized_accuracy_stochastic</th>\n",
       "      <th>quantized_accuracy_adaround</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>45.170455</td>\n",
       "      <td>45.170455</td>\n",
       "      <td>62.941919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>43.181818</td>\n",
       "      <td>44.539141</td>\n",
       "      <td>60.258838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>45.549242</td>\n",
       "      <td>42.203283</td>\n",
       "      <td>62.436869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>78.282828</td>\n",
       "      <td>78.282828</td>\n",
       "      <td>89.551768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>77.020202</td>\n",
       "      <td>76.546717</td>\n",
       "      <td>90.246212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>77.462121</td>\n",
       "      <td>77.462121</td>\n",
       "      <td>90.404040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>80.271464</td>\n",
       "      <td>92.424242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.671717</td>\n",
       "      <td>79.892677</td>\n",
       "      <td>92.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>79.482323</td>\n",
       "      <td>79.071970</td>\n",
       "      <td>92.203283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>90.877525</td>\n",
       "      <td>90.877525</td>\n",
       "      <td>90.593434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>91.382576</td>\n",
       "      <td>90.877525</td>\n",
       "      <td>91.098485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>90.625000</td>\n",
       "      <td>90.561869</td>\n",
       "      <td>89.614899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.424242</td>\n",
       "      <td>92.424242</td>\n",
       "      <td>93.087121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.329545</td>\n",
       "      <td>92.108586</td>\n",
       "      <td>92.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.108586</td>\n",
       "      <td>92.013889</td>\n",
       "      <td>92.203283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.424242</td>\n",
       "      <td>92.424242</td>\n",
       "      <td>92.613636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.582071</td>\n",
       "      <td>92.897727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>92.992424</td>\n",
       "      <td>92.203283</td>\n",
       "      <td>91.887626</td>\n",
       "      <td>92.582071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    iteration  BIWIDTH  BIWIDTH_ACTIVATION  original_accuracy  \\\n",
       "0           0        4                   4          92.992424   \n",
       "6           1        4                   4          92.992424   \n",
       "7           2        4                   4          92.992424   \n",
       "1           0        4                   6          92.992424   \n",
       "8           1        4                   6          92.992424   \n",
       "9           2        4                   6          92.992424   \n",
       "2           0        4                   8          92.992424   \n",
       "10          1        4                   8          92.992424   \n",
       "11          2        4                   8          92.992424   \n",
       "3           0        6                   6          92.992424   \n",
       "12          1        6                   6          92.992424   \n",
       "13          2        6                   6          92.992424   \n",
       "4           0        6                   8          92.992424   \n",
       "14          1        6                   8          92.992424   \n",
       "15          2        6                   8          92.992424   \n",
       "5           0        8                   8          92.992424   \n",
       "16          1        8                   8          92.992424   \n",
       "17          2        8                   8          92.992424   \n",
       "\n",
       "    quantized_accuracy_nearest  quantized_accuracy_stochastic  \\\n",
       "0                    45.170455                      45.170455   \n",
       "6                    43.181818                      44.539141   \n",
       "7                    45.549242                      42.203283   \n",
       "1                    78.282828                      78.282828   \n",
       "8                    77.020202                      76.546717   \n",
       "9                    77.462121                      77.462121   \n",
       "2                    80.271464                      80.271464   \n",
       "10                   79.671717                      79.892677   \n",
       "11                   79.482323                      79.071970   \n",
       "3                    90.877525                      90.877525   \n",
       "12                   91.382576                      90.877525   \n",
       "13                   90.625000                      90.561869   \n",
       "4                    92.424242                      92.424242   \n",
       "14                   92.329545                      92.108586   \n",
       "15                   92.108586                      92.013889   \n",
       "5                    92.424242                      92.424242   \n",
       "16                   92.992424                      92.582071   \n",
       "17                   92.203283                      91.887626   \n",
       "\n",
       "    quantized_accuracy_adaround  \n",
       "0                     62.941919  \n",
       "6                     60.258838  \n",
       "7                     62.436869  \n",
       "1                     89.551768  \n",
       "8                     90.246212  \n",
       "9                     90.404040  \n",
       "2                     92.424242  \n",
       "10                    92.613636  \n",
       "11                    92.203283  \n",
       "3                     90.593434  \n",
       "12                    91.098485  \n",
       "13                    89.614899  \n",
       "4                     93.087121  \n",
       "14                    92.613636  \n",
       "15                    92.203283  \n",
       "5                     92.613636  \n",
       "16                    92.897727  \n",
       "17                    92.582071  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Experiment().run(E.AsExperiment([\n",
    "    Params(BIWIDTH=b, BIWIDTH_ACTIVATION=ba) for (b, ba) in [(4, 4), (4, 6), (4, 8), (6, 6), (6, 8), (8, 8)]\n",
    "], repetitions=REPETITIONS, with_cache=\"../results/BIWIDTH\"))().sort_values(by=['BIWIDTH', 'BIWIDTH_ACTIVATION'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1836.391866,
   "end_time": "2023-05-14T23:59:46.683749",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-14T23:29:10.291883",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
